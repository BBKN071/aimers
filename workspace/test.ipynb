{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55b7042-aeac-454d-ad87-2b0da1bb5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8220e50d-8be2-4824-a538-81b15c5cd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3720f",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1beffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(train, test):\n",
    "    \n",
    "    # 1. 필요 없는 컬럼 제거\n",
    "    non_imp_cols = ['난자 혼합 경과일',\n",
    "    '기증자 정자와 혼합된 난자 수',\n",
    "    '동결 배아 사용 여부',\n",
    "    '여성 주 불임 원인',\n",
    "    '불명확 불임 원인',\n",
    "    '부부 부 불임 원인',\n",
    "    '착상 전 유전 진단 사용 여부',\n",
    "    '시술 유형',\n",
    "    '남성 부 불임 원인',\n",
    "    '기증 배아 사용 여부',\n",
    "    '불임 원인 - 정자 운동성',\n",
    "    '남성 주 불임 원인',\n",
    "    '불임 원인 - 자궁내막증',\n",
    "    '불임 원인 - 정자 농도',\n",
    "    '여성 부 불임 원인',\n",
    "    '대리모 여부',\n",
    "    '불임 원인 - 정자 면역학적 요인',\n",
    "    '저장된 신선 난자 수',\n",
    "    '부부 주 불임 원인',\n",
    "    '착상 전 유전 검사 사용 여부',\n",
    "    '불임 원인 - 여성 요인',\n",
    "    '불임 원인 - 자궁경부 문제',\n",
    "    'PGD 시술 여부',\n",
    "    'PGS 시술 여부',\n",
    "    '난자 채취 경과일',\n",
    "    '난자 해동 경과일',\n",
    "    '불임 원인 - 정자 형태']\n",
    "    # '착상 전 유전 검사 사용 여부',\n",
    "    # '착상 전 유전 진단 사용 여부',\n",
    "    # '남성 주 불임 원인',\n",
    "    # '남성 부 불임 원인',\n",
    "    # '여성 주 불임 원인',\n",
    "    # '여성 부 불임 원인',\n",
    "    # '부부 주 불임 원인',\n",
    "    # '부부 부 불임 원인',\n",
    "    # '불명확 불임 원인',\n",
    "    # '불임 원인 - 난관 질환',\n",
    "    # '불임 원인 - 남성 요인',\n",
    "    # '불임 원인 - 배란 장애',\n",
    "    # '불임 원인 - 여성 요인',\n",
    "    # '불임 원인 - 자궁경부 문제',\n",
    "    # '불임 원인 - 자궁내막증',\n",
    "    # '불임 원인 - 정자 농도',\n",
    "    # '불임 원인 - 정자 면역학적 요인',\n",
    "    # '불임 원인 - 정자 운동성',\n",
    "    # '불임 원인 - 정자 형태',\n",
    "    # 'IVF 시술 횟수',\n",
    "    # 'DI 시술 횟수',\n",
    "    # '총 임신 횟수',\n",
    "    # 'IVF 임신 횟수',\n",
    "    # 'DI 임신 횟수',\n",
    "    # '총 출산 횟수',\n",
    "    # 'IVF 출산 횟수',\n",
    "    # 'DI 출산 횟수',\n",
    "    # 'PGD 시술 여부',\n",
    "    # 'PGS 시술 여부',\n",
    "    # '대리모 여부',\n",
    "    # '난자 채취 경과일',\n",
    "    # '배란 유도 유형',\n",
    "    # '정자 기증자 나이']\n",
    "    \n",
    "    train.drop(columns=non_imp_cols, inplace=True)\n",
    "    test.drop(columns=non_imp_cols, inplace=True)\n",
    "\n",
    "    # 미확인 원소 대체\n",
    "    train['시술 당시 나이'] = train['시술 당시 나이'].replace({'알 수 없음' : None})\n",
    "    test['시술 당시 나이'] = test['시술 당시 나이'].replace({'알 수 없음' : None})\n",
    "    train['특정 시술 유형'] = train['특정 시술 유형'].replace({'Unknown' : 'IVF'})\n",
    "    test['특정 시술 유형'] = test['특정 시술 유형'].replace({'Unknown' : 'IVF'})\n",
    "    train['난자 출처'] = train['난자 출처'].replace({'알 수 없음' : '본인 제공'})\n",
    "    test['난자 출처'] = test['난자 출처'].replace({'알 수 없음' : '본인 제공'})\n",
    "\n",
    "    # 결측치 최빈값 대체\n",
    "    train = train.apply(lambda x:x.fillna(x.mode()[0]))\n",
    "    test = test.apply(lambda x:x.fillna(x.mode()[0]))\n",
    "\n",
    "    categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\",\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\",\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\",\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "    ]\n",
    "    categorical_columns = [x for x in categorical_columns if x not in non_imp_cols]\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        train[col] = train[col].astype(str)\n",
    "        test[col] = test[col].astype(str)\n",
    "\n",
    "\n",
    "    return train, test, categorical_columns\n",
    "\n",
    "train, test, categorical_columns = preprocessing(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbd0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a6c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "X[numeric_cols] = pt.fit_transform(X[numeric_cols])\n",
    "test[numeric_cols] = pt.fit_transform(test[numeric_cols])\n",
    "\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# qt = QuantileTransformer(output_distribution='uniform', random_state=42)\n",
    "# X[numeric_cols] = qt.fit_transform(X[numeric_cols])\n",
    "# test[numeric_cols] = qt.fit_transform(test[numeric_cols])\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "# test[numeric_cols] = scaler.fit_transform(test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f613ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6becbe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_valid_numeric = X_valid[numeric_cols]\n",
    "test_numeric = test[numeric_cols]\n",
    "\n",
    "X_train_categoric = X_train[categorical_columns]\n",
    "X_valid_categoric = X_valid[categorical_columns]\n",
    "test_categoricric = test[categorical_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f18fcb",
   "metadata": {},
   "source": [
    "## catboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 하이퍼파라미터 제안\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'depth': trial.suggest_int('depth', 3, 15),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10.0),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500)\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        **params,\n",
    "        loss_function='Logloss',\n",
    "        verbose=0,\n",
    "        cat_features=categorical_columns,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_categoric, y_train,\n",
    "        eval_set=(X_valid_categoric, y_valid),\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "    \n",
    "    pred_probas = model.predict_proba(X_valid_categoric)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, pred_probas)\n",
    "    log = log_loss(y_valid, pred_probas)\n",
    "    return auc, log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e38256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 23:57:29,820] A new study created in memory with name: no-name-9119b161-ca38-4bac-9764-364b345ac9af\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1621/244303575.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "/tmp/ipykernel_1621/244303575.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10.0),\n",
      "[I 2025-02-24 00:02:27,119] Trial 0 finished with values: [0.6665871565925245, 0.5273312532071633] and parameters: {'learning_rate': 0.015487140338144011, 'depth': 14, 'l2_leaf_reg': 1.430879617396993, 'iterations': 478}.\n",
      "/tmp/ipykernel_1621/244303575.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "/tmp/ipykernel_1621/244303575.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10.0),\n",
      "[I 2025-02-24 00:02:34,535] Trial 1 finished with values: [0.6562869100953168, 0.5345838510256825] and parameters: {'learning_rate': 0.019235732951020577, 'depth': 7, 'l2_leaf_reg': 0.14908435913347465, 'iterations': 112}.\n",
      "/tmp/ipykernel_1621/244303575.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "/tmp/ipykernel_1621/244303575.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10.0),\n",
      "[W 2025-02-24 00:02:46,883] Trial 2 failed with parameters: {'learning_rate': 0.12767536300791624, 'depth': 15, 'l2_leaf_reg': 0.0995815750526871, 'iterations': 304} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1621/244303575.py\", line 18, in objective\n",
      "    model.fit(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/catboost/core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-24 00:02:46,919] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPareto front (ROC-AUC) 최적의 트라이얼들:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m study\u001b[38;5;241m.\u001b[39mbest_trials:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m15\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m10.0\u001b[39m),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     12\u001b[0m     loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_categoric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid_categoric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m pred_probas \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid_categoric)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     26\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid, pred_probas)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/catboost/core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Pareto front (ROC-AUC) 최적의 트라이얼들:\")\n",
    "for trial in study.best_trials:\n",
    "    print(\"Trial values: {} | Params: {}\".format(trial.values, trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56882b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trials[0]\n",
    "# parameters: {'learning_rate': 0.19603157179850195, 'depth': 6, 'l2_leaf_reg': 3.1113757733956238, 'iterations': 402, 'bagging_temperature': 0.056808024089444596, 'random_strength': 3.484431922663257, 'bootstrap_type': 'Bayesian'}. Best is trial 23 with value: 0.4863828367708195.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8c19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "with open('best_params_cat_data_drop2.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7498c664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7392444579670822\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trials[0].params\n",
    "\n",
    "final_model = CatBoostClassifier(\n",
    "        **best_params,\n",
    "        loss_function='Logloss',\n",
    "        verbose=0,\n",
    "        cat_features=categorical_columns,\n",
    "        random_state=42\n",
    "    )\n",
    "final_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=20)\n",
    "pred_probas = final_model.predict_proba(X_valid)[:, 1]\n",
    "print(roc_auc_score(y_valid, pred_probas))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = final_model.predict_proba(test)[:, 1]\n",
    "# print(\"예측 확률:\", pred_probas)\n",
    "\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_probas\n",
    "display(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e281944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 확률: [0.00397007 0.00292111 0.15662164 ... 0.40806849 0.19972519 0.00462067]\n"
     ]
    }
   ],
   "source": [
    "pred_probas = final_model.predict_proba(test)[:, 1]\n",
    "print(\"예측 확률:\", pred_probas)\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_probas\n",
    "sample_submission.to_csv('./submit/submit_39_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3425b",
   "metadata": {},
   "source": [
    "## lightGBM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b994f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "X[numeric_cols] = pt.fit_transform(X[numeric_cols])\n",
    "test[numeric_cols] = pt.fit_transform(test[numeric_cols])\n",
    "\n",
    "# X_train_numeric = X_train[numeric_cols]\n",
    "# X_valid_numeric = X_valid[numeric_cols]\n",
    "# test_numeric = test[numeric_cols]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "def objective(trial):\n",
    "    # LightGBM 모델의 하이퍼파라미터 제안\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1.0)\n",
    "    }\n",
    "    \n",
    "    # LGBMClassifier 모델 생성\n",
    "    model = LGBMClassifier(\n",
    "        **params,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 모델 학습 (early stopping 적용)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric='auc'\n",
    "    )\n",
    "    \n",
    "    # 검증 데이터에 대한 예측 확률 (양성 클래스 확률)\n",
    "    pred_probas = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # 두 지표 계산\n",
    "    auc = roc_auc_score(y_valid, pred_probas)\n",
    "    loss = log_loss(y_valid, pred_probas)\n",
    "    \n",
    "    # Optuna 다중 목표: 첫 번째 목표(ROC-AUC)는 최대화, 두 번째 목표(Log Loss)는 최소화\n",
    "    return auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 다중 목표 최적화를 위한 Optuna Study 생성 및 최적화 수행\n",
    "study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# 4. Pareto Front (최적의 트라이얼 목록) 출력\n",
    "print(\"Pareto Front (ROC-AUC, Log Loss) 최적의 트라이얼들:\")\n",
    "for trial in study.best_trials:\n",
    "    print(\"Trial values (ROC-AUC, Log Loss): {} | Params: {}\".format(trial.values, trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ff32db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 최적의 파라미터 추출\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "# best_params를 pickle 파일로 저장\n",
    "with open('best_params_lightgbm_yj.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 최적의 파라미터를 사용해 최종 모델 구축 (전체 데이터로 재학습 가능)\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "final_model = LGBMClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric='auc', callbacks=[early_stopping(stopping_rounds=50)])\n",
    "\n",
    "# 최종 모델의 검증 예측 및 평가 (예시)\n",
    "pred_probas_final = final_model.predict_proba(X_valid)[:, 1]\n",
    "final_auc = roc_auc_score(y_valid, pred_probas_final)\n",
    "final_loss = log_loss(y_valid, pred_probas_final)\n",
    "print(\"\\n최종 모델 평가:\")\n",
    "print(\"ROC-AUC: {:.4f}\".format(final_auc))\n",
    "print(\"Log Loss: {:.4f}\".format(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = final_model.predict_proba(test_encoded)[:, 1]\n",
    "print(\"예측 확률:\", pred_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63552938",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_probas\n",
    "sample_submission.to_csv('./submit/submit_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff873c20",
   "metadata": {},
   "source": [
    "## gradient boosting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c8437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def objective(trial):\n",
    "    # GradientBoostingClassifier의 하이퍼파라미터 제안\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
    "    }\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 검증 데이터에 대한 예측 확률(양성 클래스)\n",
    "    pred_probas = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    \n",
    "    # 두 지표 계산\n",
    "    auc = roc_auc_score(y_valid, pred_probas)\n",
    "    loss = log_loss(y_valid, pred_probas)\n",
    "    \n",
    "    # Optuna 다중 목표: 첫 번째 목표(ROC-AUC)는 최대화, 두 번째 목표(Log Loss)는 최소화\n",
    "    return auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b68ece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:40:06,765] A new study created in memory with name: no-name-c186df39-4b40-4654-80fa-e85b799f1dcf\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:45:55,435] Trial 0 finished with values: [0.7381617858046536, 0.487072578337749] and parameters: {'n_estimators': 861, 'learning_rate': 0.005545636657901878, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3, 'subsample': 0.9965520564153055, 'max_features': 0.7602478836071893}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:48:33,843] Trial 1 finished with values: [0.7327576172838004, 0.4905608766425857] and parameters: {'n_estimators': 464, 'learning_rate': 0.07542154904011822, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.7780920272187287, 'max_features': 0.971212999350699}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:49:04,040] Trial 2 finished with values: [0.72891382747696, 0.5001421892602373] and parameters: {'n_estimators': 149, 'learning_rate': 0.012385545488878536, 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 17, 'subsample': 0.8486791014756936, 'max_features': 0.8975340940932168}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:52:35,525] Trial 3 finished with values: [0.7384899281347566, 0.4866317588099231] and parameters: {'n_estimators': 638, 'learning_rate': 0.01230630551663777, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 2, 'subsample': 0.7522800155253547, 'max_features': 0.8092568010215333}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:56:05,051] Trial 4 finished with values: [0.7389235106895313, 0.4863514983879973] and parameters: {'n_estimators': 623, 'learning_rate': 0.013954208377462998, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.9598263478526632, 'max_features': 0.7744946981237728}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:57:50,444] Trial 5 finished with values: [0.7389750434434377, 0.48636044718196947] and parameters: {'n_estimators': 726, 'learning_rate': 0.02395195625784529, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7347865584855497, 'max_features': 0.7042133284577189}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 11:58:34,317] Trial 6 finished with values: [0.7376738224335327, 0.4873904934100598] and parameters: {'n_estimators': 321, 'learning_rate': 0.040995107347540874, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.7900722511217465, 'max_features': 0.8327454241043286}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:02:39,956] Trial 7 finished with values: [0.7385772793681824, 0.4864616733254785] and parameters: {'n_estimators': 952, 'learning_rate': 0.017126748289807404, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.7497970968468205, 'max_features': 0.8638442865443516}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:03:37,468] Trial 8 finished with values: [0.7332823138697825, 0.49273139215011463] and parameters: {'n_estimators': 481, 'learning_rate': 0.0067517718787095775, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.8015398996051635, 'max_features': 0.5195126683421457}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:05:02,320] Trial 9 finished with values: [0.7385899838037919, 0.4864223450769116] and parameters: {'n_estimators': 660, 'learning_rate': 0.07978578562929517, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 18, 'subsample': 0.8948813053216303, 'max_features': 0.7161321114025602}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:10:39,435] Trial 10 finished with values: [0.7285388968335718, 0.49493150256884894] and parameters: {'n_estimators': 979, 'learning_rate': 0.05602088293667192, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 16, 'subsample': 0.9414272024354482, 'max_features': 0.7162673445447707}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:11:56,180] Trial 11 finished with values: [0.7388404085815197, 0.4863018080277129] and parameters: {'n_estimators': 632, 'learning_rate': 0.05172890708880251, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8049770920459854, 'max_features': 0.5430621493099068}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:14:49,527] Trial 12 finished with values: [0.7379542157785176, 0.48689137555801254] and parameters: {'n_estimators': 865, 'learning_rate': 0.06563891907699289, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 8, 'subsample': 0.8392270807975024, 'max_features': 0.9029378210219736}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:15:41,780] Trial 13 finished with values: [0.7383555189608159, 0.486620073214256] and parameters: {'n_estimators': 155, 'learning_rate': 0.059950171166555155, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 13, 'subsample': 0.8160556341905604, 'max_features': 0.8922454490643401}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:16:26,737] Trial 14 finished with values: [0.734993222470206, 0.4924540458100545] and parameters: {'n_estimators': 141, 'learning_rate': 0.016830183910518316, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 15, 'subsample': 0.8231494004579598, 'max_features': 0.9679459709934028}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:17:21,933] Trial 15 finished with values: [0.7365519734346475, 0.48848782303218785] and parameters: {'n_estimators': 399, 'learning_rate': 0.015274021592910823, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9842776419329339, 'max_features': 0.5192059582566163}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:18:19,650] Trial 16 finished with values: [0.7370354260420797, 0.491282165651455] and parameters: {'n_estimators': 147, 'learning_rate': 0.01582802386641787, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 7, 'subsample': 0.9321853995983218, 'max_features': 0.7779823645963273}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:20:42,075] Trial 17 finished with values: [0.7388326872565603, 0.4864820093648017] and parameters: {'n_estimators': 477, 'learning_rate': 0.014333658435397956, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 7, 'subsample': 0.7945967175548546, 'max_features': 0.6952752172713844}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:21:59,606] Trial 18 finished with values: [0.7389010986750378, 0.48632733299313974] and parameters: {'n_estimators': 425, 'learning_rate': 0.058548153037221426, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.8170202050956501, 'max_features': 0.834479816123534}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:22:16,318] Trial 19 finished with values: [0.7221335095377238, 0.5222836074127246] and parameters: {'n_estimators': 149, 'learning_rate': 0.005810192722693684, 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 1, 'subsample': 0.9973562424639609, 'max_features': 0.5369213647786245}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:23:46,160] Trial 20 finished with values: [0.7383393962511071, 0.4869371294544224] and parameters: {'n_estimators': 308, 'learning_rate': 0.023641663763963757, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 20, 'subsample': 0.9607970938765692, 'max_features': 0.9417686925108946}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:26:32,199] Trial 21 finished with values: [0.7347039643810847, 0.4891574683257434] and parameters: {'n_estimators': 865, 'learning_rate': 0.08602178673763011, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 13, 'subsample': 0.7529706592777353, 'max_features': 0.7661573404084746}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:28:57,555] Trial 22 finished with values: [0.7383117255070175, 0.4870014484352818] and parameters: {'n_estimators': 591, 'learning_rate': 0.011520458049318208, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 16, 'subsample': 0.88180369528423, 'max_features': 0.8386080911824421}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:32:17,639] Trial 23 finished with values: [0.7386856026069717, 0.4864209458582509] and parameters: {'n_estimators': 517, 'learning_rate': 0.034183880865338086, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 13, 'subsample': 0.7674676067474973, 'max_features': 0.9703589409535096}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:33:00,238] Trial 24 finished with values: [0.7372705779351815, 0.4879774168148769] and parameters: {'n_estimators': 330, 'learning_rate': 0.021227719096157276, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 15, 'subsample': 0.7557945072896225, 'max_features': 0.5887811515566583}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:34:33,839] Trial 25 finished with values: [0.7382519042123503, 0.4867266806119315] and parameters: {'n_estimators': 493, 'learning_rate': 0.04477238774570614, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 10, 'subsample': 0.787841277495861, 'max_features': 0.5941586817432964}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:36:09,612] Trial 26 finished with values: [0.7381001659965032, 0.48673251997552647] and parameters: {'n_estimators': 656, 'learning_rate': 0.0860596911378257, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 16, 'subsample': 0.8480092483757851, 'max_features': 0.642750441050703}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:37:23,869] Trial 27 finished with values: [0.7385009399105361, 0.48703005526641646] and parameters: {'n_estimators': 367, 'learning_rate': 0.014968010524208725, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 11, 'subsample': 0.7542363584379257, 'max_features': 0.6492472333112738}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:38:33,814] Trial 28 finished with values: [0.7391157019773882, 0.4862781963988753] and parameters: {'n_estimators': 511, 'learning_rate': 0.027565392657154242, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 19, 'subsample': 0.7088385597011763, 'max_features': 0.5324625168340661}.\n",
      "/tmp/ipykernel_880/2782336391.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "/tmp/ipykernel_880/2782336391.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
      "/tmp/ipykernel_880/2782336391.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.5, 1.0)\n",
      "[I 2025-02-21 12:40:48,131] Trial 29 finished with values: [0.7378130659238377, 0.4873334254740597] and parameters: {'n_estimators': 812, 'learning_rate': 0.016728373768475958, 'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 14, 'subsample': 0.834946181059305, 'max_features': 0.9920833413548097}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto Front (ROC-AUC, Log Loss) 최적의 트라이얼들:\n",
      "Trial values (ROC-AUC, Log Loss): [0.7391157019773882, 0.4862781963988753] | Params: {'n_estimators': 511, 'learning_rate': 0.027565392657154242, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 19, 'subsample': 0.7088385597011763, 'max_features': 0.5324625168340661}\n"
     ]
    }
   ],
   "source": [
    "# 3. 다중 목표 최적화를 위한 Optuna Study 생성 및 최적화 수행\n",
    "study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 4. Pareto Front (최적의 트라이얼 목록) 출력\n",
    "print(\"Pareto Front (ROC-AUC, Log Loss) 최적의 트라이얼들:\")\n",
    "for trial in study.best_trials:\n",
    "    print(\"Trial values (ROC-AUC, Log Loss): {} | Params: {}\".format(trial.values, trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca755970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 최적의 파라미터 추출\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "# best_params를 pickle 파일로 저장\n",
    "with open('best_params_gbc.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"최적의 파라미터가 best_params.pkl 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5767fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 최적의 파라미터를 사용해 최종 모델 구축 (전체 데이터로 재학습 가능)\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "final_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "final_model.fit(X_train, y_train)\n",
    "# 최종 모델의 검증 예측 및 평가 (예시)\n",
    "pred_probas_final = final_model.predict_proba(X_valid)[:, 1]\n",
    "final_auc = roc_auc_score(y_valid, pred_probas_final)\n",
    "final_loss = log_loss(y_valid, pred_probas_final)\n",
    "print(\"\\n최종 모델 평가:\")\n",
    "print(\"ROC-AUC: {:.4f}\".format(final_auc))\n",
    "print(\"Log Loss: {:.4f}\".format(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95efa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = final_model.predict_proba(test_encoded)[:, 1]\n",
    "print(\"예측 확률:\", pred_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce51f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_probas\n",
    "sample_submission.to_csv('./submit/submit_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06903f3",
   "metadata": {},
   "source": [
    "## Catboost + lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb0f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        }\n",
    "        \n",
    "    # LightGBM Regressor 모델 생성\n",
    "    model = LGBMRegressor(\n",
    "        **params,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # 모델 학습\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        categorical_feature=categorical_columns\n",
    "    )\n",
    "    \n",
    "    # 검증 데이터 예측\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # RMSE 계산 (MSE의 제곱근)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "    return r2  # RMSE 값을 최소화하는 방향으로 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 다중 목표 최적화를 위한 Optuna Study 생성 및 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 4. 최적의 하이퍼파라미터 및 R² 스코어 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  R² Score: {:.4f}\".format(trial.value))\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26918431",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trials[0].params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96339c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 최적의 파라미터를 사용해 최종 모델 구축 (전체 데이터로 재학습 가능)\n",
    "best_params = study.best_trials[0].params\n",
    "\n",
    "final_model = LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train, categorical_feature=categorical_columns\n",
    ")\n",
    "\n",
    "# 최종 모델의 검증 예측 및 평가 (예시)\n",
    "pred_probas_final = final_model.predict(X_valid)\n",
    "final_r2 = r2_score(y_valid, pred_probas_final)\n",
    "print(\"\\n최종 모델 평가:\")\n",
    "print(\"  R² Score: {:.4f}\".format(final_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c00338",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = final_model.predict(test_encoded)\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_probas\n",
    "sample_submission.to_csv('./submit/submit_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffe9ea3-2339-451c-8424-bbce482f4498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
